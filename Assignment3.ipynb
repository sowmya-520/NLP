{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLfWmnmZ/IijqjOSHb0F1B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmya-520/NLP/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3\n",
        "\n",
        "NLP ASSIGNMENT - 3\n",
        "\n",
        "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
        "\n",
        "QUESTIONS:\n",
        "\n",
        "Convert the above paragraph into vectors using:\n",
        "\n",
        "i) Word2vec\n",
        "\n",
        "ii) USE\n",
        "\n",
        "iii) ELMO\n",
        "\n",
        "iv) GP2\n",
        "\n",
        "v) Sentence-BERT\n",
        "\n",
        "2.Find named entities (NER) for the above paragraph?\n",
        "\n",
        "3.Find similar sentences (repeated sentences) from the above paragraph? (Cosine Similarity, use BERT to encode)\n",
        "\n",
        "4.Explain POS tagging with HMM? Tag POS for the above paragraph?"
      ],
      "metadata": {
        "id": "gvvRkEeZm_NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**importing libraries**"
      ],
      "metadata": {
        "id": "hiSXL39Xn2PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required packages\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwLmZgc4gkrw",
        "outputId": "a4cc0573-a882-437b-eed2-a159f2f70ffa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "TGjJjzNnd01b",
        "outputId": "c90f7c87-b56f-4be5-d247-6adda2ba7dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\\nParagraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "para1 = '''A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
        "'''\n",
        "para1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def essay_to_sentences(paragraph):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(paragraph.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    return sentences\n",
        "\n",
        "sentences=essay_to_sentences(para1)\n",
        "\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwmBFL3XguEP",
        "outputId": "1393e7b3-8e66-4fb0-8db7-db22a1ec109d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic.',\n",
              " 'Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.',\n",
              " 'This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.',\n",
              " 'Paragraphs can contain many different kinds of information.',\n",
              " 'A paragraph could contain a series of brief examples or a single long illustration of a general point.',\n",
              " 'It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects.',\n",
              " 'Regardless of the kind of information they contain, all paragraphs share certain characteristics.',\n",
              " 'One of the most important of these is a topic sentence.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**word2vec**"
      ],
      "metadata": {
        "id": "SJZLm08UptoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordvecs=[nltk.word_tokenize(s) for s in sentences]\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops_words=list(set(stopwords.words(\"english\")))\n",
        "\n",
        "for i in wordvecs:\n",
        "  for j in i:\n",
        "    if j in stops_words:\n",
        "      i.remove(j)\n",
        "    elif len(j)==1:\n",
        "      i.remove(j)\n",
        "\n",
        "model=gensim.models.Word2Vec(wordvecs,min_count=1)\n",
        "model.wv['One']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkAZYe-RgyXo",
        "outputId": "ad160594-d0ee-491f-d79c-4cfc60fece18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.9905363e-03,  3.2525830e-05,  4.6356223e-03,  3.5325957e-03,\n",
              "        7.8084250e-04,  4.4373954e-03, -3.4779713e-03, -2.1390442e-03,\n",
              "       -4.9122507e-03,  4.8014275e-03,  2.4188107e-03,  1.5632996e-03,\n",
              "        3.7586838e-03, -4.8933462e-03,  4.0561548e-03, -3.5086449e-03,\n",
              "        3.9567328e-03, -9.2933973e-04, -2.6234775e-03,  3.3943991e-03,\n",
              "        4.8837094e-03,  3.7235676e-03,  1.6813488e-03, -3.0337723e-03,\n",
              "       -2.4970234e-03,  1.2520752e-03, -2.5157928e-03,  4.8966296e-03,\n",
              "        3.8070909e-03,  2.5595209e-04,  4.7797910e-03, -3.7298302e-04,\n",
              "        2.1928415e-04,  2.8041115e-03, -6.7418805e-05,  2.9508504e-03,\n",
              "       -4.5518945e-03,  4.0989122e-04, -3.7082350e-03,  1.8745083e-03,\n",
              "       -1.3437374e-03, -1.8144712e-03,  6.2515895e-04, -3.3185596e-04,\n",
              "        2.4274341e-03, -4.3288190e-03, -2.1085022e-03,  6.2112993e-04,\n",
              "       -1.4143061e-06,  8.6159800e-04,  2.5397788e-03, -2.5008030e-03,\n",
              "       -8.4305397e-04, -3.9815041e-03, -2.7705652e-03,  3.0836316e-03,\n",
              "       -4.1717957e-03,  2.3563325e-03, -1.1284668e-03, -3.6102908e-03,\n",
              "        3.6206839e-03, -1.6961860e-03, -1.8460072e-03,  2.3074087e-03,\n",
              "        2.5373949e-03, -2.7810987e-03, -3.4035056e-05, -3.1935244e-03,\n",
              "       -7.0900953e-04,  1.6359105e-03,  2.2613730e-03,  7.5952976e-04,\n",
              "        4.5692502e-03, -3.1094437e-03,  1.8899296e-03, -1.1550746e-03,\n",
              "       -2.5153283e-03,  3.8986313e-03, -4.9607554e-03,  3.3978431e-03,\n",
              "       -2.4576874e-03, -3.5633792e-03,  8.2124496e-04,  2.8927221e-03,\n",
              "       -1.5705161e-03,  5.9896505e-05,  2.2963535e-03,  3.1855481e-04,\n",
              "        2.7723375e-03,  1.4993080e-03, -3.0387631e-03,  4.4216290e-03,\n",
              "       -2.0127832e-03,  1.0872920e-03, -7.5621734e-04, -3.8820889e-03,\n",
              "       -3.5368304e-03, -3.4914291e-03, -1.7697507e-03, -3.3139251e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USE**"
      ],
      "metadata": {
        "id": "_-aTwu-Ypyqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "vect=hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "metadata": {
        "id": "QMCLQmhMiH8Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_vectors=vect(sentences)\n",
        "print(\"shape= \",res_vectors[0].shape)\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(res_vectors[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U13jIf0DiUhw",
        "outputId": "bb7ddb24-dd21-4f38-cc2a-285f3ebd0706"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=  (512,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted as : \n",
            "[ 1.16849625e-02 -3.06057241e-02  6.11633621e-02  8.47723782e-02\n",
            " -5.83404116e-03  2.84162583e-03  2.59479079e-02  3.90261016e-03\n",
            " -5.55586144e-02  5.68111017e-02 -8.95012915e-03 -4.50471742e-03\n",
            " -6.06310219e-02  3.18566561e-02 -6.86047673e-02 -9.39451605e-02\n",
            " -4.23613675e-02  3.93056758e-02 -9.02280435e-02 -5.53663708e-02\n",
            " -1.92777591e-03  5.99909946e-02  9.42121912e-03  6.07980080e-02\n",
            " -5.22598810e-03  1.28727769e-02 -2.15456802e-02 -4.93354201e-02\n",
            " -6.26406254e-05 -4.05308828e-02  7.90260956e-02 -5.32253552e-03\n",
            " -2.70440103e-03 -1.01282876e-02 -6.41689077e-02  2.35941112e-02\n",
            "  4.94743027e-02  1.76912714e-02 -7.69228023e-03  2.03443561e-02\n",
            "  1.55387642e-02  4.64376137e-02  3.61865610e-02  4.38465513e-02\n",
            "  6.95741251e-02  2.37604640e-02 -1.20333163e-03 -4.55584005e-02\n",
            " -3.44719514e-02  1.63743664e-02 -2.70779571e-03  5.60244247e-02\n",
            "  4.04605555e-04 -1.96648743e-02 -3.91405225e-02 -9.61555261e-03\n",
            "  2.14325567e-03  5.61527051e-02  2.82766800e-02  1.80720557e-02\n",
            "  1.23768335e-03 -3.25148106e-02  4.19939868e-02  6.37653470e-02\n",
            "  5.56223281e-02  1.44277038e-02  4.99182940e-02 -1.93575602e-02\n",
            "  5.64282686e-02 -6.90750107e-02  1.60085864e-03  2.10034382e-02\n",
            "  3.52526866e-02  6.35948032e-02 -7.65628293e-02  5.87279573e-02\n",
            " -4.10688967e-02  3.31177264e-02 -2.83569773e-03  7.48986285e-03\n",
            " -3.19783837e-02 -6.25580326e-02  4.89425063e-02  3.36479768e-02\n",
            "  2.12714802e-02  4.28446010e-03 -9.05695604e-04 -4.36472381e-03\n",
            " -9.23611373e-02 -3.89573909e-02  3.30829546e-02  9.61314328e-03\n",
            "  2.15857457e-02 -1.47692738e-02  1.38847362e-02  8.47374573e-02\n",
            " -8.47435743e-02 -4.44485135e-02  7.54610896e-02  1.65129639e-02\n",
            "  2.31740028e-02 -2.84717027e-02 -6.77682534e-02  4.24248539e-02\n",
            " -1.49503639e-02  8.38018022e-03  5.18886261e-02  3.92066427e-02\n",
            " -4.66535538e-02 -2.45939568e-02  7.14570459e-04 -3.46494955e-03\n",
            "  2.36652531e-02  3.31293717e-02 -5.71687194e-03  4.09859084e-02\n",
            " -8.35536122e-02 -1.66684203e-02 -3.52722546e-03  1.73547920e-02\n",
            "  2.53550429e-02 -2.66782343e-02 -2.51309760e-02 -4.68712226e-02\n",
            "  3.96435633e-02 -6.68356707e-03 -3.46517414e-02 -2.81814747e-02\n",
            "  4.19962592e-02 -3.24101560e-02  2.40438618e-02 -5.47125330e-03\n",
            "  2.89679859e-02  6.99753016e-02  3.75228934e-02 -8.82184058e-02\n",
            "  6.07019104e-03 -6.91123381e-02 -1.74329411e-02  2.53294185e-02\n",
            " -7.28369653e-02  2.37329248e-02  4.66296040e-02  4.23278362e-02\n",
            "  5.21276854e-02 -3.55561008e-03 -1.40108112e-02  2.05670819e-02\n",
            "  7.19132945e-02 -7.66954198e-02 -3.90844978e-02 -6.40899539e-02\n",
            "  2.43546739e-02  7.42070824e-02  2.84557994e-02 -7.93435350e-02\n",
            " -1.47222299e-02  6.70734374e-03  1.02058453e-02  1.25844004e-02\n",
            "  3.10074463e-02 -4.17215005e-02  6.03259280e-02  6.22179657e-02\n",
            "  2.10032854e-02 -1.65604409e-02  4.09301184e-03 -3.35808508e-02\n",
            "  7.28031471e-02  6.09729216e-02  4.15963680e-03  8.54913294e-02\n",
            "  1.31301386e-02 -6.34360593e-03 -5.07236086e-02  7.03543425e-02\n",
            "  3.73295508e-02  3.42008099e-02 -3.79101220e-05 -6.27389550e-02\n",
            "  4.80309166e-02 -2.81623453e-02 -7.19844848e-02  1.20989718e-02\n",
            " -4.26681973e-02  1.97790973e-02 -1.35227693e-02 -5.43040968e-02\n",
            " -4.83289734e-02 -2.65408792e-02  8.23441967e-02  5.54602556e-02\n",
            "  7.81148598e-02 -4.00112383e-03  2.02439595e-02  1.84899904e-02\n",
            " -1.52465552e-02  2.18962617e-02  3.17285061e-02  7.06312209e-02\n",
            "  3.70562938e-03  2.40870584e-02  1.94732298e-03 -7.16169551e-03\n",
            " -2.68035308e-02  3.17232199e-02  8.41562822e-02  2.63580363e-02\n",
            " -2.52104383e-02 -1.10670505e-02 -5.61276972e-02  3.97370607e-02\n",
            " -5.51151559e-02  6.12288788e-02  5.18368185e-02 -1.64934061e-02\n",
            "  1.84759719e-03  6.83429018e-02  6.94626421e-02  3.78927328e-02\n",
            " -5.02522849e-02 -2.57219560e-02  7.02316985e-02  3.36491764e-02\n",
            "  5.98843908e-04 -3.67769860e-02  4.44350578e-02  1.09023489e-02\n",
            "  4.34661806e-02 -6.98098615e-02 -2.62659937e-02  2.23396681e-02\n",
            "  9.15533490e-03 -6.15917817e-02  8.41568410e-02  3.92306149e-02\n",
            "  8.92866924e-02  1.28770871e-02  1.39245335e-02 -5.68395145e-02\n",
            " -7.46639073e-02  3.65591794e-02  1.06103569e-02 -6.25316799e-02\n",
            "  1.77653804e-02 -6.67557791e-02 -6.54299483e-02  4.47695665e-02\n",
            " -2.96407975e-02 -2.13827938e-02  3.60825099e-02 -8.18173289e-02\n",
            " -1.40964659e-02  1.33901071e-02  3.07124238e-02 -9.41405520e-02\n",
            "  3.03545557e-02 -2.68576015e-02  1.81658212e-02 -3.67770456e-02\n",
            "  3.33085321e-02  9.13278088e-02 -1.94911137e-02 -1.07955048e-02\n",
            " -9.28005297e-03 -4.06911317e-03  1.46724582e-02 -4.92432937e-02\n",
            "  1.71533599e-02 -5.45221604e-02 -6.61364123e-02 -7.90792033e-02\n",
            "  2.79751848e-02  3.62354182e-02  4.38262261e-02  1.96567848e-02\n",
            " -6.87819719e-02  2.44918838e-02  7.10261464e-02  9.12545249e-02\n",
            "  6.29523173e-02  1.67941395e-02  6.54826015e-02 -4.73535480e-03\n",
            " -4.48028259e-02 -1.61742717e-02  2.20355503e-02 -4.16113250e-02\n",
            "  1.13562578e-02 -3.63931730e-02 -2.76284125e-02  2.01357082e-02\n",
            " -8.22386295e-02 -2.58972924e-02 -4.15527485e-02 -5.79356104e-02\n",
            "  7.72935897e-03  4.06588875e-02 -1.13817379e-02  4.38650511e-02\n",
            " -1.07141351e-02 -4.62955013e-02  5.65050580e-02 -6.18267581e-02\n",
            " -3.84526514e-02 -4.90092300e-02  5.23114428e-02 -5.73057532e-02\n",
            " -1.15798069e-02  5.35165612e-03  2.78308783e-02 -4.59580906e-02\n",
            "  4.34778668e-02 -1.71735901e-02 -1.64880324e-02 -3.88848744e-02\n",
            " -6.44626282e-03  8.33479688e-02  3.65923531e-02  2.13971846e-02\n",
            " -2.59777717e-02 -6.10677898e-02  5.17178811e-02 -5.09534888e-02\n",
            " -8.41620713e-02 -2.87301522e-02 -8.05718377e-02  7.76726380e-02\n",
            "  4.12431993e-02 -3.67930308e-02  2.71156337e-02 -6.33788630e-02\n",
            "  2.25471333e-02 -3.28405760e-02 -9.11881123e-03  5.93739860e-02\n",
            " -7.64809921e-03  8.31474736e-03 -6.06926996e-03  6.88906759e-02\n",
            "  5.30840755e-02 -3.67045030e-03 -2.88561042e-02 -4.73021902e-02\n",
            " -9.18376073e-02 -8.83618277e-03  7.96945244e-02  5.93198873e-02\n",
            "  3.53019126e-02  7.12427963e-03 -7.07041398e-02  1.53526133e-02\n",
            "  4.09509540e-02  7.17417430e-03  7.37813115e-02  3.77231091e-02\n",
            " -9.00578871e-02 -3.24093476e-02  1.16494400e-02 -3.81786190e-02\n",
            "  2.34411880e-02 -2.10632607e-02 -7.03862309e-02  1.52054429e-03\n",
            " -1.61061902e-02  6.18526712e-02  7.94101879e-02  5.88107808e-03\n",
            " -1.51091265e-02 -3.21430154e-02  7.52918655e-03 -1.46267074e-03\n",
            "  6.74486533e-02  8.21412131e-02  1.35811316e-02  1.83010716e-02\n",
            "  3.14529203e-02  3.24921198e-02 -1.57691799e-02 -4.33157757e-02\n",
            " -4.35551889e-02 -1.21416962e-02  3.53560923e-03  4.30949815e-02\n",
            " -2.73922738e-02  2.91704386e-02 -8.02248865e-02 -2.86437925e-02\n",
            " -1.37747321e-02 -3.15168649e-02 -1.11740930e-02 -2.86995899e-02\n",
            " -3.92324254e-02  5.84819168e-02  5.46791963e-03 -2.98926216e-02\n",
            "  5.75806433e-03 -1.14696641e-02 -1.36440666e-02  2.66200826e-02\n",
            "  2.02789833e-03  3.45309786e-02 -5.55947497e-02  4.45481129e-02\n",
            "  7.75338989e-03  3.83887403e-02 -3.04163452e-02 -3.68546396e-02\n",
            " -5.83012551e-02  4.55890112e-02  4.12782058e-02 -2.69910265e-02\n",
            "  6.76821470e-02 -4.02726382e-02 -1.81559287e-02 -3.41260359e-02\n",
            "  5.10256812e-02  1.71382017e-02 -4.04663477e-03 -5.73980510e-02\n",
            "  1.24875875e-02 -6.49295226e-02 -7.56197646e-02  1.49736758e-02\n",
            "  2.50920095e-02  6.72384948e-02  5.28013073e-02  9.06193629e-02\n",
            " -5.04058525e-02  4.25336212e-02  2.04153005e-02 -6.48177508e-03\n",
            "  2.96379179e-02  4.65666084e-03 -4.00494002e-02 -5.69047444e-02\n",
            " -1.83908269e-02  2.06823051e-02  3.54514085e-02 -9.10554156e-02\n",
            " -2.56894790e-02  8.05327892e-02 -6.87960237e-02 -1.90876797e-02\n",
            " -4.92995023e-04 -1.21406829e-02 -8.38927459e-03  8.40041507e-03\n",
            "  7.14359358e-02 -1.60705671e-02  5.72944395e-02  3.03892116e-03\n",
            " -6.78497627e-02 -6.15831316e-02  7.88365304e-02 -6.56958222e-02\n",
            "  4.85723317e-02  6.67115971e-02  8.34890753e-02 -5.98137565e-02\n",
            " -1.69116613e-02  8.24893564e-02 -6.09520636e-03 -3.53485122e-02\n",
            " -2.27540918e-02 -9.13803279e-02 -4.53933701e-02 -8.25901609e-03\n",
            "  4.79642525e-02  7.68054426e-02 -3.04625053e-02 -1.50704673e-02\n",
            " -2.30549723e-02 -8.25553108e-03 -6.91695418e-03 -4.25843114e-04\n",
            "  3.37524414e-02 -2.74846219e-02 -9.42037441e-03 -6.28642179e-03\n",
            " -2.22888868e-02 -1.39351822e-02  6.23975182e-03 -8.72642696e-02\n",
            "  1.45548712e-02 -8.02355036e-02 -3.33043113e-02 -5.46392463e-02\n",
            "  4.86492999e-02  2.14732923e-02  3.27529870e-02 -1.53550990e-02\n",
            "  5.31828627e-02  1.56334788e-02  3.91776711e-02  6.98064500e-03\n",
            " -3.86222564e-02 -2.99131311e-02  1.69515181e-02  5.10435551e-02\n",
            "  3.60743441e-02 -5.03288209e-02  5.67543395e-02  7.83906430e-02\n",
            "  6.19171113e-02 -1.52612077e-02 -1.87837277e-02 -3.86123806e-02\n",
            "  6.28505573e-02 -8.64175484e-02  2.50503188e-04  5.48274927e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ELMO**"
      ],
      "metadata": {
        "id": "q2bHIIzxwG0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "#1024 sized vectors\n",
        "elmo=hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)\n",
        "embeddings=elmo(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "init=tf.initialize_all_variables()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "print(\"\\n\\n\")\n",
        "print(sess.run(embeddings[0]))\n",
        "print(\"shape=\",embeddings[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhAmEBoiaYQ",
        "outputId": "361de4a0-d923-4b19-8b0f-6aed2ef69955"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:243: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "[[ 0.29287004 -0.14378013 -0.32574052 ... -0.39559263 -0.35758853\n",
            "  -0.03588088]\n",
            " [-0.59441584  0.09640743  0.50537694 ...  0.22031914  0.269769\n",
            "   0.46307266]\n",
            " [-0.1708326  -0.18744111 -0.27626696 ... -0.67550904  0.25389987\n",
            "   0.6540271 ]\n",
            " ...\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]]\n",
            "shape= (32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GP2**"
      ],
      "metadata": {
        "id": "gYLDZwqYv69F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "res_vectors=gptokenizer.encode(para1,add_special_tokens=False,return_tensors=\"pt\")\n",
        "print(\"shape=\",res_vectors.shape)\n",
        "res_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epC2_ATfii7Y",
        "outputId": "fe282e86-ac9a-4cba-a844-f9bb9d1c4105"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= torch.Size([1, 173])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
              "           290, 24870,    11,   290,   389,   477,  3519,   284,   257,  2060,\n",
              "          7243,    13, 16699,   790,  3704,   286,  3597,   345,   466,   326,\n",
              "           318,  2392,   621,   257,  1178, 13439,   815,   307,  8389,   656,\n",
              "         23549,    13,   770,   318,   780, 23549,   905,   257,  9173,   810,\n",
              "           262, 45944,  3279,   286,   281, 14268,  2221,   290,   886,    11,\n",
              "           290,  4145,  1037,   262,  9173,   766,   262,  4009,   286,   262,\n",
              "         14268,   290, 13180,   663,  1388,  2173,    13,   198, 10044,  6111,\n",
              "            82,   460,  3994,   867,  1180,  6982,   286,  1321,    13,   317,\n",
              "          7322,   714,  3994,   257,  2168,   286,  4506,  6096,   393,   257,\n",
              "          2060,   890, 20936,   286,   257,  2276,   966,    13,   632,  1244,\n",
              "          6901,   257,  1295,    11,  2095,    11,   393,  1429,    26,  6664,\n",
              "           378,   257,  2168,   286,  2995,    26,  8996,   393,  6273,   734,\n",
              "           393,   517,  1243,    26, 36509,  3709,   656,  9376,    26,   393,\n",
              "          6901,  5640,   290,  3048,    13, 22250,   286,   262,  1611,   286,\n",
              "          1321,   484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,\n",
              "          1881,   286,   262,   749,  1593,   286,   777,   318,   257,  7243,\n",
              "          6827,    13,   198]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sentencebert model**"
      ],
      "metadata": {
        "id": "L6JNcqfRwbR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "embeddings=bert(sentences)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhWY1GKFjeob",
        "outputId": "46383a27-d230-440e-9900-5b2c3c0b1a4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"keras_layer/StatefulPartitionedCall:0\", shape=(None, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape=\",embeddings[0].shape)\n",
        "#each sentence is converted into vector having 128 values\n",
        "print(\"The sentence in the paragraph: \",sentences[0],\"\\n is converted into vector  as : \\n{}\".format(embeddings[0]))\n",
        "shape= (128,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb6k10C5jn6A",
        "outputId": "8f9f592e-206d-4ef3-f67b-2c6d443ad767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= (128,)\n",
            "The sentence in the paragraph:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted into vector  as : \n",
            "Tensor(\"strided_slice_3:0\", shape=(128,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "7pyLAmYkxHfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "ner=spacy.load('en_core_web_sm')\n",
        "res=ner(para1)\n",
        "\n",
        "for word in res.ents:\n",
        "  print(word.text,word.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTACbVvMhikX",
        "outputId": "3e536e21-a2e7-493e-ab6e-c0bc5ad279ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two CARDINAL\n",
            "One CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('GPE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_sYWSZUhpHn",
        "outputId": "846303c9-deef-4c94-c4fb-21b1c7a7d882"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#better visualisation of entity recognition\n",
        "displacy.render(res,style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "7kQV4n0thv8o",
        "outputId": "eb44894b-0516-461a-f737-eeb20c2c0c57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.</br>Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of the most important of these is a topic sentence.</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# question3"
      ],
      "metadata": {
        "id": "6HXe7TFbxVsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "VzX9_UXuh3_3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "se_embeddings = sbert_model.encode(sentences)\n",
        "q1_vec= sbert_model.encode(sentences[0])\n",
        "\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "for sent in sentences:\n",
        "  sim = cosine(q1_vec, sbert_model.encode([sent])[0])\n",
        "  if sim>0.6:\n",
        "    print(\"Sentence1 =\",sentences[0],\"\\n \\nSentence2=\", sent, \"\\n\\nsimilarity = \", sim,end=\"\\n ----------------------------- \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ZwpYdRlF05",
        "outputId": "2bc35c80-7897-46fb-ef79-3e7e79d97302"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            "\n",
            "similarity =  1.0\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n",
            "\n",
            "similarity =  0.6477537\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph could contain a series of brief examples or a single long illustration of a general point. \n",
            "\n",
            "similarity =  0.69272894\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
            "\n",
            "similarity =  0.78738403\n",
            " ----------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#question4"
      ],
      "metadata": {
        "id": "QQyF_i4xxkDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Tagging for Above Given Paragraph\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        " \n",
        "txt = \"A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic.\" \\\n",
        "    \"Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.\" \\\n",
        "    \"This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\" \\\n",
        "    \"Paragraphs can contain many different kinds of information.\" \\\n",
        "    \"A paragraph could contain a series of brief examples or a single long illustration of a general point.\" \\\n",
        "    \"It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects.\" \\\n",
        "    \"Regardless of the kind of information they contain, all paragraphs share certain characteristics.\" \\\n",
        "    \"One of the most important of these is a topic sentence.\"\n",
        " \n",
        "# sent_tokenize is one of instances of\n",
        "# PunktSentenceTokenizer from the nltk.tokenize.punkt module\n",
        " \n",
        "tokenized = sent_tokenize(txt)\n",
        "for i in tokenized:\n",
        "     \n",
        "    # Word tokenizers is used to find the words\n",
        "    # and punctuation in a string\n",
        "    wordsList = nltk.word_tokenize(i)\n",
        " \n",
        "    # removing stop words from wordList\n",
        "    wordsList = [w for w in wordsList if not w in stop_words]\n",
        " \n",
        "    #  Using a Tagger. Which is part-of-speech\n",
        "    # tagger or POS-tagger.\n",
        "    tagged = nltk.pos_tag(wordsList)\n",
        " \n",
        "    print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7Q8w_Ql3op",
        "outputId": "3e31d3c5-7821-4f88-9ca9-83d8251216ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A', 'DT'), ('paragraph', 'NN'), ('series', 'NN'), ('sentences', 'NNS'), ('organized', 'VBN'), ('coherent', 'NN'), (',', ','), ('related', 'VBN'), ('single', 'JJ'), ('topic.Almost', 'NN'), ('every', 'DT'), ('piece', 'NN'), ('writing', 'VBG'), ('longer', 'JJR'), ('sentences', 'NNS'), ('organized', 'VBD'), ('paragraphs.This', 'NN'), ('paragraphs', 'NN'), ('show', 'NN'), ('reader', 'NN'), ('subdivisions', 'NNS'), ('essay', 'VBP'), ('begin', 'JJ'), ('end', 'NN'), (',', ','), ('thus', 'RB'), ('help', 'NN'), ('reader', 'VB'), ('see', 'VB'), ('organization', 'NN'), ('essay', 'VB'), ('grasp', 'NN'), ('main', 'JJ'), ('points.Paragraphs', 'NN'), ('contain', 'VBP'), ('many', 'JJ'), ('different', 'JJ'), ('kinds', 'NNS'), ('information.A', 'VBP'), ('paragraph', 'NN'), ('could', 'MD'), ('contain', 'VB'), ('series', 'NN'), ('brief', 'NN'), ('examples', 'VBZ'), ('single', 'JJ'), ('long', 'JJ'), ('illustration', 'NN'), ('general', 'JJ'), ('point.It', 'NN'), ('might', 'MD'), ('describe', 'VB'), ('place', 'NN'), (',', ','), ('character', 'NN'), (',', ','), ('process', 'NN'), (';', ':'), ('narrate', 'JJ'), ('series', 'NN'), ('events', 'NNS'), (';', ':'), ('compare', 'VB'), ('contrast', 'NN'), ('two', 'CD'), ('things', 'NNS'), (';', ':'), ('classify', 'VB'), ('items', 'NNS'), ('categories', 'NNS'), (';', ':'), ('describe', 'VB'), ('causes', 'VBZ'), ('effects.Regardless', 'JJ'), ('kind', 'NN'), ('information', 'NN'), ('contain', 'NN'), (',', ','), ('paragraphs', 'JJ'), ('share', 'NN'), ('certain', 'JJ'), ('characteristics.One', 'NN'), ('important', 'JJ'), ('topic', 'NN'), ('sentence', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}